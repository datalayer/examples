# Transformers text generation

This example demonstrates how to leverage Datalayer's **GPU kernels** to accelerate text generation using **Gemma 7B** model and the HuggingFace Transformers library. We will be using Gemma-7b and Gemma-7b-it which is the instruct fine-tuned version of Gemma-7b.

Text generation can be viewed akin to performing inference tasks, where the model interprets input prompts to generate meaningful and contextually appropriate text responses.