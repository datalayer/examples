{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "This script is designed to download a YouTube video, detect faces in the video frames, and create an output video with the detected faces highlighted. It uses the `pytube`, `moviepy`, and `OpenCV` libraries for video processing and face detection. The code is organized into functions to perform specific tasks, such as downloading the video, parallelizing face detection, and cleaning up temporary files. It is powered by the Ray framework for parallel and distributed computing.\n",
    "\n",
    "Note that the sound is not preserved in the output video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray_ease as rez\n",
    "import cv2\n",
    "import moviepy.editor\n",
    "import pytube\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the MODEL_PATH environment variable to the Haar Cascade model's location\n",
    "tmp = os.getenv(\"MODEL_PATH\")\n",
    "os.environ[\"MODEL_PATH\"] = tmp if tmp else \"./haarcascade_frontalface_default.xml\"\n",
    "\n",
    "OUTPUT_DIR = \"./tmp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rez.parallelize\n",
    "def detect_faces(fn, start, stop):\n",
    "    # Extract the subclip from the video\n",
    "    clip = moviepy.editor.VideoFileClip(fn).subclip(start, stop)\n",
    "\n",
    "    # Load face detector\n",
    "    face_cascade = cv2.CascadeClassifier(os.getenv(\"MODEL_PATH\"))\n",
    "\n",
    "    # Run face detector on frames\n",
    "    imgs = []\n",
    "    for img in clip.iter_frames():\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        for x, y, w, h in faces:\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        imgs.append(img)\n",
    "\n",
    "    # Create mp4 of result\n",
    "    out_clip = moviepy.editor.ImageSequenceClip(imgs, fps=clip.fps)\n",
    "    out_fn = f\"./clips/{start:04d}.mp4\"\n",
    "    out_clip.write_videofile(out_fn, logger=None)\n",
    "    return out_fn\n",
    "\n",
    "def process_video(url, limit = None):\n",
    "    print(f\"Downloading video from '{url}'\")\n",
    "    yt = pytube.YouTube(url)\n",
    "    stream = yt.streams.filter(file_extension=\"mp4\").first()\n",
    "    fn = stream.download(output_path=\"./clips/\", max_retries=5)\n",
    "\n",
    "    # Get duration\n",
    "    duration = moviepy.editor.VideoFileClip(fn).duration\n",
    "\n",
    "    # Create (start, stop) intervals\n",
    "    intervals = [(fn, offset, offset + 1) for offset in range(int(duration))]\n",
    "    if limit:\n",
    "        intervals = intervals[:limit]\n",
    "\n",
    "    print(\"Processing each range of 1s intervals in parallel using Ray\")\n",
    "    out_fns = rez.retrieve([detect_faces(*interval) for interval in intervals], parallel_progress=True, parallel_progress_kwargs={\"desc\": \"1s Intervals\"})\n",
    "\n",
    "    print(\"Converting detections to video clips\")\n",
    "    out_clips = [moviepy.editor.VideoFileClip(out_fn) for out_fn in out_fns]\n",
    "\n",
    "    print(\"Concatenating results\")\n",
    "    final_clip = moviepy.editor.concatenate_videoclips(out_clips)\n",
    "    final_fn = \"./clips/out.mp4\"\n",
    "    final_clip.write_videofile(final_fn, logger=None)\n",
    "\n",
    "    # Return the full image data\n",
    "    with open(final_fn, \"rb\") as f:\n",
    "        return os.path.basename(fn), f.read()\n",
    "    \n",
    "def main(youtube_url: str = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\", output_dir = OUTPUT_DIR, limit = None):\n",
    "    fn, movie_data = process_video(youtube_url, limit=limit)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    abs_fn = os.path.join(output_dir, f\"{os.getenv('RAY_EASE')}_\"+fn)\n",
    "    print(f\"writing results to {abs_fn}\")\n",
    "    with open(abs_fn, \"wb\") as f:\n",
    "        f.write(movie_data)\n",
    "\n",
    "def clean(folder = \"./clips/\"):\n",
    "    print(\"Cleaning clips directory.\")\n",
    "\n",
    "    for i in os.listdir(folder):\n",
    "        os.remove(os.path.join(folder, i))\n",
    "    os.rmdir(folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "rez.init(\"ray\")\n",
    "\n",
    "# To process a smaller part of the video use the `limit` argument and set it\n",
    "# to the number of 1s interval you want to process, by default `limit=None`\n",
    "# to process the complete video\n",
    "main()\n",
    "\n",
    "total = time.time() - start\n",
    "print(f\"duration = {int((total//60)//60)}h {int((total//60)%60)}min {int(total%60)}s\")\n",
    "\n",
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp clips/000*.mp4 content/local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can tell from the resulting video, this face detection model is not state of the art. It has plenty of false positives (non-faces being labeled faces) and false negatives (real faces not being labeled). For better model, consider a modern one based on deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
