{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction tuning Mistral 7B on Alpaca dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to fine-tune [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1) using the [Alapca dataset](https://huggingface.co/datasets/tatsu-lab/alpaca). Mistral 7B is a large language model (LLM) that contains 7.3 billion parameters and is one of the most powerful models for its size. However, this base model is not instruction-tuned, meaning it may struggle to follow instructions and perform specific tasks.\n",
    "\n",
    "The Alpaca dataset consists of 52,000 instructions and demonstrations generated by OpenAI's text-davinci-003 engine. These can be used for instruction tuning, helping language models to better understand and follow instructions. By fine-tuning Mistral 7B on the Alpaca dataset, the model will significantly improve its capabilities to perform tasks such as conversation and answering questions accurately.\n",
    "\n",
    "We will utilize [torchtune](https://github.com/pytorch/torchtune), a PyTorch-native library designed to facilitate experimentation with LLMs, for the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T14:24:16.552945Z",
     "iopub.status.busy": "2024-06-26T14:24:16.551743Z",
     "iopub.status.idle": "2024-06-26T14:24:25.605472Z",
     "shell.execute_reply": "2024-06-26T14:24:25.604084Z",
     "shell.execute_reply.started": "2024-06-26T14:24:16.552891Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.2.2 in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (4.10.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.2.2) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Collecting torchtune\n",
      "  Downloading torchtune-0.1.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting datasets (from torchtune)\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting huggingface-hub (from torchtune)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors (from torchtune)\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting sentencepiece (from torchtune)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tiktoken (from torchtune)\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting blobfile>=2 (from torchtune)\n",
      "  Downloading blobfile-2.1.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from torchtune) (4.66.2)\n",
      "Collecting omegaconf (from torchtune)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting torchao==0.1 (from torchtune)\n",
      "  Downloading torchao-0.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from torchao==0.1->torchtune) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchao==0.1->torchtune) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from torchao==0.1->torchtune) (24.0)\n",
      "Requirement already satisfied: pycryptodomex~=3.8 in /opt/conda/lib/python3.11/site-packages (from blobfile>=2->torchtune) (3.20.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /opt/conda/lib/python3.11/site-packages (from blobfile>=2->torchtune) (2.2.1)\n",
      "Collecting lxml~=4.9 (from blobfile>=2->torchtune)\n",
      "  Downloading lxml-4.9.4-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: filelock~=3.0 in /opt/conda/lib/python3.11/site-packages (from blobfile>=2->torchtune) (3.13.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->torchtune) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets->torchtune) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->torchtune) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->torchtune) (2.2.1)\n",
      "Collecting requests>=2.32.2 (from datasets->torchtune)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from torchtune)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets->torchtune)\n",
      "  Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->torchtune)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->torchtune) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets->torchtune) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets->torchtune) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->torchtune) (4.10.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->torchtune)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting regex>=2022.1.18 (from tiktoken->torchtune)\n",
      "  Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->torchtune) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->torchtune) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->torchtune) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->torchtune) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->torchtune) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->torchtune) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->torchtune) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets->torchtune) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->torchtune) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->torchtune) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->torchtune) (2024.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch->torchao==0.1->torchtune) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchao==0.1->torchtune) (12.4.127)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->torchao==0.1->torchtune) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->torchao==0.1->torchtune) (1.3.0)\n",
      "Downloading torchtune-0.1.1-py3-none-any.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchao-0.1-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blobfile-2.1.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-4.9.4-cp311-cp311-manylinux_2_28_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m131.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=cbe95de22700a5801c6c77c11cca0c9c2bb4192b4ca5ba05e023c65a92d450ba\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: sentencepiece, antlr4-python3-runtime, xxhash, tqdm, safetensors, requests, regex, omegaconf, multiprocess, lxml, tiktoken, huggingface-hub, blobfile, torchao, datasets, torchtune\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.2\n",
      "    Uninstalling tqdm-4.66.2:\n",
      "      Successfully uninstalled tqdm-4.66.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 blobfile-2.1.1 datasets-2.20.0 huggingface-hub-0.23.4 lxml-4.9.4 multiprocess-0.70.16 omegaconf-2.3.0 regex-2024.5.15 requests-2.32.3 safetensors-0.4.3 sentencepiece-0.2.0 tiktoken-0.7.0 torchao-0.1 torchtune-0.1.1 tqdm-4.66.4 xxhash-3.4.1\n"
     ]
    }
   ],
   "source": [
    "! pip install torch==2.2.2\n",
    "! pip install torchtune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T14:24:25.609414Z",
     "iopub.status.busy": "2024-06-26T14:24:25.608395Z",
     "iopub.status.idle": "2024-06-26T14:24:25.939574Z",
     "shell.execute_reply": "2024-06-26T14:24:25.938226Z",
     "shell.execute_reply.started": "2024-06-26T14:24:25.609357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 26 14:24:25 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100S-PCIE-32GB          On  |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   44C    P0             28W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# GPU check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Mistral 7B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to donwload Mistral 7B. This can be achieved through torchtune with the following cell.\n",
    "\n",
    "> **_NOTE:_** Set your environment variable `<HF_TOKEN>` or pass in --hf-token to the command in order to validate your access. You can find your token at https://huggingface.co/settings/tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T14:41:37.170349Z",
     "iopub.status.busy": "2024-06-26T14:41:37.168529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring files matching the following patterns: *.safetensors\n",
      "Fetching 12 files:   0%|                                 | 0/12 [00:00<?, ?it/s]\n",
      "model.safetensors.index.json: 100%|████████| 25.1k/25.1k [00:00<00:00, 44.4MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin.index.json: 100%|████████| 23.9k/23.9k [00:00<00:00, 7.47MB/s]\u001b[A\n",
      "\n",
      ".gitattributes: 100%|██████████████████████| 1.52k/1.52k [00:00<00:00, 7.06MB/s]\u001b[A\n",
      "Fetching 12 files:   8%|██                       | 1/12 [00:00<00:03,  3.65it/s]\n",
      "config.json: 100%|█████████████████████████████| 571/571 [00:00<00:00, 2.68MB/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|███████████████████| 116/116 [00:00<00:00, 623kB/s]\u001b[A\n",
      "\n",
      "README.md: 100%|███████████████████████████| 1.39k/1.39k [00:00<00:00, 7.80MB/s]\u001b[A\n",
      "\n",
      "tokenizer.model: 100%|███████████████████████| 493k/493k [00:00<00:00, 26.7MB/s]\u001b[A\n",
      "\n",
      "tokenizer.json:   0%|                               | 0.00/1.80M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "special_tokens_map.json: 100%|████████████████| 72.0/72.0 [00:00<00:00, 330kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tokenizer_config.json: 100%|███████████████████| 967/967 [00:00<00:00, 4.48MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|             | 0.00/9.94G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   0%|             | 0.00/5.06G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "tokenizer.json: 100%|██████████████████████| 1.80M/1.80M [00:00<00:00, 5.45MB/s]\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 10.5M/9.94G [00:00<11:08, 14.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   0%|    | 10.5M/5.06G [00:00<05:48, 14.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 21.0M/9.94G [00:00<06:25, 25.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 31.5M/9.94G [00:01<04:57, 33.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   0%|    | 21.0M/5.06G [00:01<03:44, 22.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 41.9M/9.94G [00:01<04:16, 38.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 52.4M/9.94G [00:01<03:41, 44.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 31.5M/5.06G [00:01<03:39, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 62.9M/9.94G [00:01<03:42, 44.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 73.4M/9.94G [00:01<03:39, 45.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 41.9M/5.06G [00:01<03:26, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 83.9M/9.94G [00:02<03:42, 44.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 94.4M/9.94G [00:02<03:39, 44.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 52.4M/5.06G [00:02<03:27, 24.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 105M/9.94G [00:02<03:38, 45.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 62.9M/5.06G [00:02<03:21, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 115M/9.94G [00:02<04:03, 40.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 126M/9.94G [00:03<03:47, 43.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 73.4M/5.06G [00:03<03:47, 22.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 136M/9.94G [00:03<04:05, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 147M/9.94G [00:03<03:56, 41.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 157M/9.94G [00:04<04:09, 39.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   2%|    | 83.9M/5.06G [00:03<04:20, 19.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 168M/9.94G [00:04<03:59, 40.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 178M/9.94G [00:04<04:11, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 189M/9.94G [00:04<04:02, 40.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   2%|    | 94.4M/5.06G [00:04<04:49, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 199M/9.94G [00:05<04:11, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 210M/9.94G [00:05<04:02, 40.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 220M/9.94G [00:05<04:06, 39.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   2%|     | 105M/5.06G [00:05<05:31, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 231M/9.94G [00:05<04:02, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 241M/9.94G [00:06<03:54, 41.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 252M/9.94G [00:06<03:49, 42.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 262M/9.94G [00:06<03:53, 41.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   2%|     | 115M/5.06G [00:06<05:57, 13.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 273M/9.94G [00:06<04:07, 39.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 283M/9.94G [00:07<04:08, 38.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 294M/9.94G [00:07<04:18, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   2%|     | 126M/5.06G [00:07<06:09, 13.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 304M/9.94G [00:07<04:42, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 315M/9.94G [00:08<04:42, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   3%|▏    | 136M/5.06G [00:08<06:15, 13.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 325M/9.94G [00:08<04:41, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 336M/9.94G [00:08<05:03, 31.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 346M/9.94G [00:09<04:34, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   3%|▏    | 147M/5.06G [00:08<06:11, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 357M/9.94G [00:09<04:35, 34.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 367M/9.94G [00:09<04:35, 34.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   3%|▏    | 157M/5.06G [00:09<06:14, 13.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 377M/9.94G [00:09<04:35, 34.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 388M/9.94G [00:10<04:34, 34.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 398M/9.94G [00:10<04:34, 34.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   3%|▏    | 168M/5.06G [00:10<06:13, 13.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 409M/9.94G [00:10<04:32, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 419M/9.94G [00:11<04:35, 34.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 430M/9.94G [00:11<04:17, 36.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 178M/5.06G [00:11<06:11, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 440M/9.94G [00:11<05:02, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 451M/9.94G [00:12<04:10, 37.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 461M/9.94G [00:12<04:16, 37.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 189M/5.06G [00:12<06:13, 13.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 472M/9.94G [00:12<04:04, 38.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 482M/9.94G [00:12<04:12, 37.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 493M/9.94G [00:13<04:17, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 199M/5.06G [00:13<06:39, 12.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 503M/9.94G [00:13<04:20, 36.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 514M/9.94G [00:13<04:07, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 524M/9.94G [00:13<04:13, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 535M/9.94G [00:14<04:16, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 210M/5.06G [00:14<06:56, 11.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 545M/9.94G [00:14<04:19, 36.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 556M/9.94G [00:14<04:06, 38.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 566M/9.94G [00:15<04:35, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 220M/5.06G [00:15<06:56, 11.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 577M/9.94G [00:15<05:34, 28.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   5%|▏    | 231M/5.06G [00:15<06:53, 11.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 587M/9.94G [00:16<06:33, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 598M/9.94G [00:16<07:18, 21.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   5%|▏    | 241M/5.06G [00:16<06:43, 12.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 608M/9.94G [00:17<08:09, 19.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   5%|▏    | 252M/5.06G [00:17<06:29, 12.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 619M/9.94G [00:18<08:43, 17.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   5%|▎    | 262M/5.06G [00:18<06:25, 12.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 629M/9.94G [00:18<09:07, 17.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   5%|▎    | 273M/5.06G [00:19<06:19, 12.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 640M/9.94G [00:19<09:22, 16.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 283M/5.06G [00:20<06:12, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 650M/9.94G [00:20<09:15, 16.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 661M/9.94G [00:20<09:10, 16.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 294M/5.06G [00:20<06:13, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 671M/9.94G [00:21<09:22, 16.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 304M/5.06G [00:21<06:04, 13.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 682M/9.94G [00:22<09:15, 16.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 315M/5.06G [00:22<06:07, 12.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 692M/9.94G [00:22<09:08, 16.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 325M/5.06G [00:23<05:59, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 703M/9.94G [00:23<09:04, 17.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 713M/9.94G [00:23<09:00, 17.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 336M/5.06G [00:24<06:02, 13.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 724M/9.94G [00:24<09:30, 16.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 346M/5.06G [00:24<05:56, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 734M/9.94G [00:25<10:05, 15.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 357M/5.06G [00:25<06:11, 12.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 744M/9.94G [00:26<10:22, 14.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 367M/5.06G [00:26<06:27, 12.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 755M/9.94G [00:27<10:31, 14.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 377M/5.06G [00:27<06:26, 12.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 765M/9.94G [00:27<10:19, 14.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 776M/9.94G [00:28<10:05, 15.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 388M/5.06G [00:28<06:20, 12.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 786M/9.94G [00:28<09:50, 15.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 398M/5.06G [00:29<06:16, 12.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 797M/9.94G [00:29<09:41, 15.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 409M/5.06G [00:29<06:04, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 807M/9.94G [00:30<09:34, 15.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 419M/5.06G [00:30<05:55, 13.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 818M/9.94G [00:30<09:20, 16.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 828M/9.94G [00:31<09:10, 16.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 430M/5.06G [00:31<05:48, 13.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 839M/9.94G [00:32<09:11, 16.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 440M/5.06G [00:32<05:43, 13.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 849M/9.94G [00:32<09:10, 16.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 451M/5.06G [00:32<05:42, 13.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 860M/9.94G [00:33<09:03, 16.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 461M/5.06G [00:33<05:40, 13.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 870M/9.94G [00:33<08:57, 16.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 881M/9.94G [00:34<08:53, 17.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 472M/5.06G [00:34<06:11, 12.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 891M/9.94G [00:35<09:09, 16.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▍    | 482M/5.06G [00:35<06:44, 11.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 902M/9.94G [00:36<09:59, 15.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 912M/9.94G [00:36<10:14, 14.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▍    | 493M/5.06G [00:37<07:17, 10.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 923M/9.94G [00:37<10:07, 14.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 933M/9.94G [00:38<10:00, 15.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▍    | 503M/5.06G [00:38<07:33, 10.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 944M/9.94G [00:38<09:54, 15.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▌    | 514M/5.06G [00:39<07:41, 9.86MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 954M/9.94G [00:39<09:46, 15.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 965M/9.94G [00:40<09:29, 15.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▌    | 524M/5.06G [00:40<07:42, 9.82MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 975M/9.94G [00:40<09:19, 16.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 986M/9.94G [00:41<09:15, 16.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 535M/5.06G [00:41<07:46, 9.71MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▌    | 996M/9.94G [00:42<09:05, 16.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 545M/5.06G [00:42<07:43, 9.75MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍   | 1.01G/9.94G [00:42<09:36, 15.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍   | 1.02G/9.94G [00:43<10:16, 14.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 556M/5.06G [00:43<07:44, 9.70MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍   | 1.03G/9.94G [00:44<10:30, 14.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 566M/5.06G [00:44<07:43, 9.70MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍   | 1.04G/9.94G [00:45<10:46, 13.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 577M/5.06G [00:45<07:35, 9.86MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.05G/9.94G [00:45<10:36, 14.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.06G/9.94G [00:46<11:06, 13.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 587M/5.06G [00:46<07:26, 10.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.07G/9.94G [00:47<11:54, 12.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 598M/5.06G [00:47<07:33, 9.85MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.08G/9.94G [00:48<12:10, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 608M/5.06G [00:48<07:41, 9.66MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.09G/9.94G [00:49<12:21, 11.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 619M/5.06G [00:50<07:36, 9.73MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.10G/9.94G [00:50<12:23, 11.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 629M/5.06G [00:51<07:25, 9.95MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.11G/9.94G [00:51<12:14, 12.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 640M/5.06G [00:52<07:13, 10.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.12G/9.94G [00:52<12:14, 12.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 650M/5.06G [00:52<07:03, 10.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.13G/9.94G [00:53<12:10, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.14G/9.94G [00:53<12:09, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 661M/5.06G [00:53<06:56, 10.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.15G/9.94G [00:54<12:08, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 671M/5.06G [00:54<06:45, 10.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.16G/9.94G [00:55<11:59, 12.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 682M/5.06G [00:55<06:41, 10.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.17G/9.94G [00:56<12:01, 12.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 692M/5.06G [00:56<06:38, 11.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.18G/9.94G [00:57<11:55, 12.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 703M/5.06G [00:57<06:31, 11.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.20G/9.94G [00:58<11:36, 12.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 713M/5.06G [00:58<06:26, 11.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.21G/9.94G [00:59<11:31, 12.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 724M/5.06G [00:59<06:22, 11.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.22G/9.94G [00:59<11:08, 13.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.23G/9.94G [01:00<10:43, 13.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 734M/5.06G [01:00<06:15, 11.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.24G/9.94G [01:01<10:19, 14.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|▋    | 744M/5.06G [01:01<06:04, 11.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.25G/9.94G [01:01<09:44, 14.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|▋    | 755M/5.06G [01:01<05:52, 12.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.26G/9.94G [01:02<09:19, 15.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|▊    | 765M/5.06G [01:02<05:38, 12.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.27G/9.94G [01:02<08:55, 16.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.28G/9.94G [01:03<08:24, 17.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|▊    | 776M/5.06G [01:03<05:20, 13.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.29G/9.94G [01:03<07:51, 18.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 786M/5.06G [01:04<05:02, 14.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.30G/9.94G [01:04<07:23, 19.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 797M/5.06G [01:04<04:45, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.31G/9.94G [01:04<07:00, 20.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.32G/9.94G [01:05<06:42, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 807M/5.06G [01:05<04:27, 15.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.33G/9.94G [01:05<06:16, 22.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 818M/5.06G [01:05<04:11, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.34G/9.94G [01:06<05:56, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 828M/5.06G [01:06<03:55, 18.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.35G/9.94G [01:06<05:39, 25.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.36G/9.94G [01:06<05:15, 27.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  17%|▊    | 839M/5.06G [01:06<03:42, 19.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.37G/9.94G [01:07<05:05, 28.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  17%|▊    | 849M/5.06G [01:07<03:26, 20.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.38G/9.94G [01:07<04:51, 29.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  17%|▊    | 860M/5.06G [01:07<03:13, 21.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.39G/9.94G [01:07<04:37, 30.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.41G/9.94G [01:07<04:23, 32.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  17%|▊    | 870M/5.06G [01:07<03:01, 23.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.42G/9.94G [01:08<04:08, 34.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  17%|▊    | 881M/5.06G [01:08<02:51, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.43G/9.94G [01:08<04:05, 34.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  18%|▉    | 891M/5.06G [01:08<02:44, 25.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.44G/9.94G [01:08<03:57, 35.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.45G/9.94G [01:09<03:45, 37.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  18%|▉    | 902M/5.06G [01:09<02:52, 24.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.46G/9.94G [01:09<03:37, 39.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.47G/9.94G [01:09<03:30, 40.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  18%|▉    | 912M/5.06G [01:09<02:55, 23.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.48G/9.94G [01:09<03:38, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.49G/9.94G [01:10<03:46, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  18%|▉    | 923M/5.06G [01:10<02:53, 23.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.50G/9.94G [01:10<04:08, 34.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  18%|▉    | 933M/5.06G [01:10<02:52, 23.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.51G/9.94G [01:10<04:26, 31.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  19%|▉    | 944M/5.06G [01:10<02:47, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.52G/9.94G [01:11<04:54, 28.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  19%|▉    | 954M/5.06G [01:11<02:46, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.53G/9.94G [01:11<04:57, 28.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  19%|▉    | 965M/5.06G [01:11<02:41, 25.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▌   | 1.54G/9.94G [01:12<05:00, 28.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  19%|▉    | 975M/5.06G [01:12<02:38, 25.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▌   | 1.55G/9.94G [01:12<05:01, 27.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  19%|▉    | 986M/5.06G [01:12<02:35, 26.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.56G/9.94G [01:12<05:01, 27.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  20%|▉    | 996M/5.06G [01:12<02:32, 26.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.57G/9.94G [01:13<05:01, 27.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  20%|▊   | 1.01G/5.06G [01:13<02:29, 27.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.58G/9.94G [01:13<05:01, 27.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  20%|▊   | 1.02G/5.06G [01:13<02:53, 23.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.59G/9.94G [01:14<05:00, 27.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.60G/9.94G [01:14<05:01, 27.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  20%|▊   | 1.03G/5.06G [01:14<03:20, 20.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.61G/9.94G [01:14<05:36, 24.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  20%|▊   | 1.04G/5.06G [01:15<03:38, 18.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.63G/9.94G [01:15<05:58, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.64G/9.94G [01:15<06:00, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  21%|▊   | 1.05G/5.06G [01:15<03:50, 17.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.65G/9.94G [01:16<06:00, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  21%|▊   | 1.06G/5.06G [01:16<03:52, 17.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.66G/9.94G [01:16<06:00, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.67G/9.94G [01:17<05:59, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  21%|▊   | 1.07G/5.06G [01:17<03:57, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.68G/9.94G [01:17<05:58, 23.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  21%|▊   | 1.08G/5.06G [01:17<03:56, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.69G/9.94G [01:18<05:57, 23.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  22%|▊   | 1.09G/5.06G [01:18<03:54, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.70G/9.94G [01:18<05:56, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.71G/9.94G [01:19<05:55, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  22%|▊   | 1.10G/5.06G [01:18<03:52, 17.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.72G/9.94G [01:19<06:15, 21.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  22%|▉   | 1.11G/5.06G [01:19<03:56, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.73G/9.94G [01:20<06:44, 20.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  22%|▉   | 1.12G/5.06G [01:20<03:54, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.74G/9.94G [01:20<07:01, 19.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  22%|▉   | 1.13G/5.06G [01:20<04:07, 15.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.75G/9.94G [01:21<07:01, 19.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.76G/9.94G [01:21<06:59, 19.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  23%|▉   | 1.14G/5.06G [01:21<04:20, 15.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.77G/9.94G [01:22<06:57, 19.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  23%|▉   | 1.15G/5.06G [01:22<04:25, 14.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.78G/9.94G [01:22<06:55, 19.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  23%|▉   | 1.16G/5.06G [01:23<04:22, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.79G/9.94G [01:23<06:53, 19.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.80G/9.94G [01:24<06:51, 19.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  23%|▉   | 1.17G/5.06G [01:23<04:18, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.81G/9.94G [01:24<06:50, 19.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  23%|▉   | 1.18G/5.06G [01:24<04:15, 15.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.82G/9.94G [01:25<06:49, 19.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  24%|▉   | 1.20G/5.06G [01:25<04:07, 15.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.84G/9.94G [01:25<06:47, 19.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  24%|▉   | 1.21G/5.06G [01:25<04:05, 15.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|▋   | 1.85G/9.94G [01:26<06:39, 20.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|▋   | 1.86G/9.94G [01:26<06:34, 20.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  24%|▉   | 1.22G/5.06G [01:26<03:58, 16.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.87G/9.94G [01:27<06:37, 20.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  24%|▉   | 1.23G/5.06G [01:27<03:54, 16.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.88G/9.94G [01:27<06:39, 20.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  24%|▉   | 1.24G/5.06G [01:27<03:50, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.89G/9.94G [01:28<06:38, 20.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  25%|▉   | 1.25G/5.06G [01:28<03:50, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.90G/9.94G [01:28<06:32, 20.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  25%|▉   | 1.26G/5.06G [01:28<03:48, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.91G/9.94G [01:29<06:30, 20.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.92G/9.94G [01:29<06:35, 20.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  25%|█   | 1.27G/5.06G [01:29<03:46, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.93G/9.94G [01:30<06:34, 20.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  25%|█   | 1.28G/5.06G [01:30<03:43, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.94G/9.94G [01:30<06:28, 20.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  25%|█   | 1.29G/5.06G [01:30<03:42, 17.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.95G/9.94G [01:31<06:25, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  26%|█   | 1.30G/5.06G [01:31<03:40, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.96G/9.94G [01:31<06:27, 20.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  26%|█   | 1.31G/5.06G [01:31<03:38, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.97G/9.94G [01:32<06:18, 21.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.98G/9.94G [01:32<06:18, 21.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  26%|█   | 1.32G/5.06G [01:32<03:40, 17.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.99G/9.94G [01:33<06:13, 21.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  26%|█   | 1.33G/5.06G [01:33<03:38, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.00G/9.94G [01:33<06:04, 21.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  26%|█   | 1.34G/5.06G [01:33<03:36, 17.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.01G/9.94G [01:34<05:58, 22.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.02G/9.94G [01:34<05:52, 22.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  27%|█   | 1.35G/5.06G [01:34<03:32, 17.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.03G/9.94G [01:34<05:49, 22.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  27%|█   | 1.36G/5.06G [01:34<03:31, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.04G/9.94G [01:35<05:42, 23.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  27%|█   | 1.37G/5.06G [01:35<03:26, 17.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.06G/9.94G [01:35<05:29, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.07G/9.94G [01:36<05:24, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  27%|█   | 1.38G/5.06G [01:36<03:24, 18.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.08G/9.94G [01:36<06:36, 19.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  28%|█   | 1.39G/5.06G [01:36<03:39, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.09G/9.94G [01:37<05:39, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  28%|█   | 1.41G/5.06G [01:37<03:07, 19.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.10G/9.94G [01:37<04:24, 29.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.11G/9.94G [01:37<04:25, 29.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  28%|█   | 1.42G/5.06G [01:37<03:00, 20.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.12G/9.94G [01:38<04:21, 29.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  28%|█▏  | 1.43G/5.06G [01:38<02:58, 20.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.13G/9.94G [01:38<04:27, 29.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  28%|█▏  | 1.44G/5.06G [01:38<02:52, 21.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▊   | 2.14G/9.94G [01:38<04:49, 27.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▏  | 1.45G/5.06G [01:39<02:47, 21.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▊   | 2.15G/9.94G [01:39<05:02, 25.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▏  | 1.46G/5.06G [01:39<02:42, 22.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▊   | 2.16G/9.94G [01:39<05:07, 25.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▏  | 1.47G/5.06G [01:39<02:33, 23.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▊   | 2.17G/9.94G [01:40<05:04, 25.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▏  | 1.48G/5.06G [01:40<02:28, 24.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.18G/9.94G [01:40<05:01, 25.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▏  | 1.49G/5.06G [01:40<02:27, 24.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.19G/9.94G [01:40<05:00, 25.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.20G/9.94G [01:41<04:55, 26.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  30%|█▏  | 1.50G/5.06G [01:41<02:52, 20.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.21G/9.94G [01:41<04:48, 26.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  30%|█▏  | 1.51G/5.06G [01:42<03:09, 18.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.22G/9.94G [01:42<05:42, 22.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  30%|█▏  | 1.52G/5.06G [01:42<03:22, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.23G/9.94G [01:43<07:32, 17.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  30%|█▏  | 1.53G/5.06G [01:43<03:29, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  30%|█▏  | 1.54G/5.06G [01:44<03:30, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.24G/9.94G [01:44<08:44, 14.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  31%|█▏  | 1.55G/5.06G [01:44<03:31, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.25G/9.94G [01:45<09:24, 13.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  31%|█▏  | 1.56G/5.06G [01:45<03:29, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.26G/9.94G [01:46<09:48, 13.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  31%|█▏  | 1.57G/5.06G [01:46<03:30, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  31%|█▎  | 1.58G/5.06G [01:46<03:29, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.28G/9.94G [01:46<10:01, 12.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  31%|█▎  | 1.59G/5.06G [01:47<03:26, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.29G/9.94G [01:47<10:06, 12.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  32%|█▎  | 1.60G/5.06G [01:47<03:25, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  32%|█▎  | 1.61G/5.06G [01:48<03:26, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.30G/9.94G [01:48<10:13, 12.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  32%|█▎  | 1.63G/5.06G [01:49<03:25, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.31G/9.94G [01:49<10:14, 12.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  32%|█▎  | 1.64G/5.06G [01:49<03:23, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.32G/9.94G [01:50<10:13, 12.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▎  | 1.65G/5.06G [01:50<03:22, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▎  | 1.66G/5.06G [01:50<03:22, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.33G/9.94G [01:51<10:16, 12.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▎  | 1.67G/5.06G [01:51<03:22, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.34G/9.94G [01:52<10:16, 12.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▎  | 1.68G/5.06G [01:52<03:20, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▎  | 1.69G/5.06G [01:52<03:17, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.35G/9.94G [01:53<11:11, 11.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▎  | 1.70G/5.06G [01:53<03:14, 17.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▎  | 1.71G/5.06G [01:53<03:11, 17.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.36G/9.94G [01:54<11:28, 11.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▎  | 1.72G/5.06G [01:54<03:09, 17.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.37G/9.94G [01:55<11:22, 11.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▎  | 1.73G/5.06G [01:55<03:19, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.38G/9.94G [01:56<11:11, 11.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▎  | 1.74G/5.06G [01:56<03:29, 15.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  35%|█▍  | 1.75G/5.06G [01:56<03:28, 15.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.39G/9.94G [01:56<10:57, 11.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  35%|█▍  | 1.76G/5.06G [01:57<03:40, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.40G/9.94G [01:57<10:48, 11.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  35%|█▍  | 1.77G/5.06G [01:58<03:55, 14.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.41G/9.94G [01:58<10:32, 11.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  35%|█▍  | 1.78G/5.06G [01:59<03:59, 13.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.42G/9.94G [01:59<10:21, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  35%|█▍  | 1.79G/5.06G [02:00<04:08, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.43G/9.94G [02:00<10:15, 12.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.44G/9.94G [02:01<10:12, 12.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▍  | 1.80G/5.06G [02:01<04:52, 11.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.45G/9.94G [02:01<10:09, 12.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▍  | 1.81G/5.06G [02:02<05:30, 9.83MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.46G/9.94G [02:02<10:04, 12.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.47G/9.94G [02:03<09:59, 12.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▍  | 1.82G/5.06G [02:04<06:00, 9.00MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.49G/9.94G [02:04<09:51, 12.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.50G/9.94G [02:05<09:46, 12.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▍  | 1.84G/5.06G [02:05<06:44, 7.98MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.51G/9.94G [02:06<09:31, 13.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.52G/9.94G [02:06<09:16, 13.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.53G/9.94G [02:07<08:56, 13.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▍  | 1.85G/5.06G [02:07<07:30, 7.15MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.54G/9.94G [02:08<08:37, 14.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.55G/9.94G [02:08<08:11, 15.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.56G/9.94G [02:09<07:51, 15.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.57G/9.94G [02:09<07:24, 16.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  37%|█▍  | 1.86G/5.06G [02:10<09:13, 5.80MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.58G/9.94G [02:10<07:01, 17.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.59G/9.94G [02:10<06:41, 18.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.60G/9.94G [02:11<06:17, 19.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.61G/9.94G [02:11<05:57, 20.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.62G/9.94G [02:12<05:35, 21.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.63G/9.94G [02:12<05:17, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.64G/9.94G [02:13<05:01, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  37%|█▍  | 1.87G/5.06G [02:13<11:04, 4.81MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.65G/9.94G [02:13<04:45, 25.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.66G/9.94G [02:13<04:33, 26.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.67G/9.94G [02:14<04:26, 27.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.68G/9.94G [02:14<04:40, 25.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.69G/9.94G [02:14<04:49, 25.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.71G/9.94G [02:15<04:42, 25.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.72G/9.94G [02:15<04:37, 26.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.73G/9.94G [02:16<04:44, 25.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.74G/9.94G [02:16<04:37, 26.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  37%|█▍  | 1.88G/5.06G [02:16<12:48, 4.15MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.75G/9.94G [02:16<04:19, 27.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.76G/9.94G [02:17<04:18, 27.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.77G/9.94G [02:17<04:17, 27.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.78G/9.94G [02:18<04:16, 27.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.79G/9.94G [02:18<04:03, 29.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█▏  | 2.80G/9.94G [02:18<04:06, 29.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█▏  | 2.81G/9.94G [02:19<03:56, 30.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█▏  | 2.82G/9.94G [02:19<04:00, 29.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  37%|█▍  | 1.89G/5.06G [02:19<13:29, 3.93MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|█▏  | 2.83G/9.94G [02:19<03:50, 30.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.84G/9.94G [02:20<03:56, 30.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.85G/9.94G [02:20<03:47, 31.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.86G/9.94G [02:20<03:42, 31.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.87G/9.94G [02:21<03:49, 30.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.88G/9.94G [02:21<03:43, 31.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.89G/9.94G [02:21<03:44, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.90G/9.94G [02:22<03:43, 31.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.92G/9.94G [02:22<03:39, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  37%|█▍  | 1.90G/5.06G [02:22<13:46, 3.83MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.93G/9.94G [02:22<03:41, 31.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.94G/9.94G [02:23<03:40, 31.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.95G/9.94G [02:23<03:36, 32.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.96G/9.94G [02:23<03:32, 32.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.97G/9.94G [02:23<03:40, 31.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.98G/9.94G [02:24<03:36, 32.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.99G/9.94G [02:24<03:32, 32.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.00G/9.94G [02:24<03:36, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  38%|█▌  | 1.91G/5.06G [02:24<13:16, 3.96MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.01G/9.94G [02:25<03:36, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.02G/9.94G [02:25<03:33, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.03G/9.94G [02:25<03:29, 32.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.04G/9.94G [02:26<03:37, 31.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.05G/9.94G [02:26<03:33, 32.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  38%|█▌  | 1.92G/5.06G [02:26<11:58, 4.38MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.06G/9.94G [02:26<03:31, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.07G/9.94G [02:27<03:33, 32.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.08G/9.94G [02:27<03:33, 32.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.09G/9.94G [02:27<03:30, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  38%|█▌  | 1.93G/5.06G [02:28<10:22, 5.04MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.10G/9.94G [02:28<03:27, 33.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▎  | 3.11G/9.94G [02:28<03:33, 31.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▎  | 3.12G/9.94G [02:28<03:30, 32.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.14G/9.94G [02:29<03:27, 32.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  38%|█▌  | 1.94G/5.06G [02:29<08:48, 5.91MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.15G/9.94G [02:29<03:25, 33.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.16G/9.94G [02:29<03:27, 32.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.95G/5.06G [02:29<07:25, 7.00MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.17G/9.94G [02:30<03:29, 32.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.18G/9.94G [02:30<03:25, 32.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.19G/9.94G [02:30<03:23, 33.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.96G/5.06G [02:30<06:17, 8.22MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.20G/9.94G [02:31<03:20, 33.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.21G/9.94G [02:31<03:18, 33.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.97G/5.06G [02:31<05:19, 9.68MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.22G/9.94G [02:31<03:17, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.23G/9.94G [02:31<03:16, 34.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.98G/5.06G [02:31<04:33, 11.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.24G/9.94G [02:32<03:18, 33.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.99G/5.06G [02:32<03:54, 13.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.25G/9.94G [02:32<03:12, 34.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.26G/9.94G [02:32<03:11, 34.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  40%|█▌  | 2.00G/5.06G [02:32<03:26, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.27G/9.94G [02:33<03:10, 35.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.28G/9.94G [02:33<03:05, 36.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  40%|█▌  | 2.01G/5.06G [02:33<03:00, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.29G/9.94G [02:33<03:02, 36.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  40%|█▌  | 2.02G/5.06G [02:33<02:41, 18.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.30G/9.94G [02:34<03:04, 36.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  40%|█▌  | 2.03G/5.06G [02:34<02:25, 20.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.31G/9.94G [02:34<02:59, 36.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.32G/9.94G [02:34<02:56, 37.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  40%|█▌  | 2.04G/5.06G [02:34<02:11, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.33G/9.94G [02:34<02:58, 37.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  41%|█▌  | 2.06G/5.06G [02:34<02:00, 25.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.34G/9.94G [02:35<02:49, 38.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  41%|█▋  | 2.07G/5.06G [02:35<01:50, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.36G/9.94G [02:35<02:52, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  41%|█▋  | 2.08G/5.06G [02:35<01:42, 29.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.37G/9.94G [02:35<02:46, 39.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  41%|█▋  | 2.09G/5.06G [02:35<01:36, 30.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.38G/9.94G [02:35<02:45, 39.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  41%|█▋  | 2.10G/5.06G [02:35<01:29, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.39G/9.94G [02:36<02:44, 39.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 2.11G/5.06G [02:36<01:24, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.40G/9.94G [02:36<02:40, 40.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 2.12G/5.06G [02:36<01:20, 36.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.41G/9.94G [02:36<02:37, 41.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 2.13G/5.06G [02:36<01:15, 38.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▍  | 3.42G/9.94G [02:36<02:32, 42.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 2.14G/5.06G [02:36<01:12, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▍  | 3.43G/9.94G [02:37<02:37, 41.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 2.15G/5.06G [02:37<01:09, 41.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.44G/9.94G [02:37<02:31, 42.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  43%|█▋  | 2.16G/5.06G [02:37<01:08, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.45G/9.94G [02:37<02:29, 43.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  43%|█▋  | 2.17G/5.06G [02:37<01:06, 43.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.46G/9.94G [02:37<02:27, 43.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  43%|█▋  | 2.18G/5.06G [02:37<01:02, 46.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.47G/9.94G [02:38<02:26, 44.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  43%|█▋  | 2.19G/5.06G [02:37<01:00, 47.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.48G/9.94G [02:38<02:15, 47.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  43%|█▋  | 2.20G/5.06G [02:38<00:57, 49.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.49G/9.94G [02:38<02:17, 47.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  44%|█▋  | 2.21G/5.06G [02:38<00:58, 48.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.50G/9.94G [02:38<02:33, 41.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  44%|█▊  | 2.22G/5.06G [02:38<01:01, 46.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.51G/9.94G [02:39<02:55, 36.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  44%|█▊  | 2.23G/5.06G [02:38<01:08, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  44%|█▊  | 2.24G/5.06G [02:39<01:06, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.52G/9.94G [02:39<03:25, 31.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  45%|█▊  | 2.25G/5.06G [02:39<01:10, 40.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  45%|█▊  | 2.26G/5.06G [02:39<01:08, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.53G/9.94G [02:40<03:58, 26.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  45%|█▊  | 2.28G/5.06G [02:40<01:09, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  45%|█▊  | 2.29G/5.06G [02:40<01:08, 40.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.54G/9.94G [02:40<04:24, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  45%|█▊  | 2.30G/5.06G [02:40<01:06, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  46%|█▊  | 2.31G/5.06G [02:40<01:09, 39.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.55G/9.94G [02:41<04:30, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  46%|█▊  | 2.32G/5.06G [02:41<01:16, 36.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.57G/9.94G [02:41<04:44, 22.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  46%|█▊  | 2.33G/5.06G [02:41<01:31, 29.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.58G/9.94G [02:42<04:43, 22.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  46%|█▊  | 2.34G/5.06G [02:42<01:31, 29.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  46%|█▊  | 2.35G/5.06G [02:42<01:27, 31.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.59G/9.94G [02:42<04:52, 21.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▊  | 2.36G/5.06G [02:42<01:24, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▊  | 2.37G/5.06G [02:42<01:22, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.60G/9.94G [02:43<04:50, 21.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▉  | 2.38G/5.06G [02:43<01:20, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.61G/9.94G [02:43<04:43, 22.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▉  | 2.39G/5.06G [02:43<01:19, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▉  | 2.40G/5.06G [02:43<01:17, 34.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.62G/9.94G [02:44<04:53, 21.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.41G/5.06G [02:44<01:16, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.42G/5.06G [02:44<01:12, 36.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.63G/9.94G [02:44<05:41, 18.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.43G/5.06G [02:44<01:22, 31.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.44G/5.06G [02:45<01:26, 30.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.64G/9.94G [02:45<06:40, 15.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.45G/5.06G [02:45<01:28, 29.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  49%|█▉  | 2.46G/5.06G [02:46<01:35, 27.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.65G/9.94G [02:46<06:59, 15.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  49%|█▉  | 2.47G/5.06G [02:46<01:45, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  49%|█▉  | 2.49G/5.06G [02:46<01:48, 23.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.66G/9.94G [02:47<07:21, 14.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  49%|█▉  | 2.50G/5.06G [02:47<01:53, 22.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.67G/9.94G [02:48<07:25, 14.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  49%|█▉  | 2.51G/5.06G [02:47<01:52, 22.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  50%|█▉  | 2.52G/5.06G [02:48<01:51, 22.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.68G/9.94G [02:48<07:38, 13.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  50%|█▉  | 2.53G/5.06G [02:48<01:51, 22.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  50%|██  | 2.54G/5.06G [02:49<01:50, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.69G/9.94G [02:49<07:36, 13.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  50%|██  | 2.55G/5.06G [02:49<01:49, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.70G/9.94G [02:50<07:34, 13.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 2.56G/5.06G [02:50<01:49, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 2.57G/5.06G [02:50<01:48, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.71G/9.94G [02:51<07:32, 13.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 2.58G/5.06G [02:51<01:47, 23.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 2.59G/5.06G [02:51<01:47, 23.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.72G/9.94G [02:51<07:30, 13.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 2.60G/5.06G [02:52<01:46, 23.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.73G/9.94G [02:52<07:29, 13.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  52%|██  | 2.61G/5.06G [02:52<01:46, 23.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  52%|██  | 2.62G/5.06G [02:53<01:51, 21.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.74G/9.94G [02:53<07:28, 13.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  52%|██  | 2.63G/5.06G [02:53<01:59, 20.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.75G/9.94G [02:54<07:27, 13.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  52%|██  | 2.64G/5.06G [02:54<02:16, 17.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.76G/9.94G [02:54<07:26, 13.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  52%|██  | 2.65G/5.06G [02:55<02:31, 16.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.77G/9.94G [02:55<07:13, 14.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  53%|██  | 2.66G/5.06G [02:55<02:33, 15.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.79G/9.94G [02:56<07:15, 14.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  53%|██  | 2.67G/5.06G [02:56<02:38, 15.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.80G/9.94G [02:57<07:04, 14.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  53%|██  | 2.68G/5.06G [02:57<02:36, 15.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.81G/9.94G [02:57<06:56, 14.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  53%|██▏ | 2.69G/5.06G [02:58<02:39, 14.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.82G/9.94G [02:58<06:49, 15.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  53%|██▏ | 2.71G/5.06G [02:58<02:37, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.83G/9.94G [02:59<06:32, 15.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.84G/9.94G [02:59<06:19, 16.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 2.72G/5.06G [02:59<02:36, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.85G/9.94G [03:00<06:09, 16.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 2.73G/5.06G [03:00<02:34, 15.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.86G/9.94G [03:00<05:50, 17.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 2.74G/5.06G [03:00<02:33, 15.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.87G/9.94G [03:01<05:37, 18.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 2.75G/5.06G [03:01<02:34, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.88G/9.94G [03:01<05:15, 19.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.89G/9.94G [03:02<04:59, 20.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 2.76G/5.06G [03:02<02:34, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.90G/9.94G [03:02<04:46, 21.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.91G/9.94G [03:03<04:31, 22.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.92G/9.94G [03:03<04:35, 21.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 2.77G/5.06G [03:03<03:10, 12.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.93G/9.94G [03:04<04:44, 21.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.94G/9.94G [03:04<04:48, 20.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 2.78G/5.06G [03:04<03:31, 10.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.95G/9.94G [03:05<04:40, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.96G/9.94G [03:05<04:45, 21.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.97G/9.94G [03:06<04:36, 21.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 2.79G/5.06G [03:05<03:42, 10.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.98G/9.94G [03:06<04:28, 22.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.00G/9.94G [03:06<04:15, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 2.80G/5.06G [03:07<03:48, 9.90MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.01G/9.94G [03:07<04:15, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.02G/9.94G [03:07<04:14, 23.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.03G/9.94G [03:08<04:02, 24.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 2.81G/5.06G [03:08<03:51, 9.74MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▌  | 4.04G/9.94G [03:08<04:05, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.05G/9.94G [03:09<03:56, 25.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.06G/9.94G [03:09<03:55, 25.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  56%|██▏ | 2.82G/5.06G [03:09<03:53, 9.60MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.07G/9.94G [03:09<03:53, 25.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.08G/9.94G [03:10<03:47, 25.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  56%|██▏ | 2.83G/5.06G [03:10<03:53, 9.58MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.09G/9.94G [03:10<03:49, 25.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.10G/9.94G [03:11<03:48, 25.6MB/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "! tune download mistralai/Mistral-7B-v0.1 \\\n",
    "--output-dir ./mistral-7B \\\n",
    "--hf-token <HF_TOKEN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference using Mistral 7B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've downloaded the base model, let's employ it to generate an answer from a text input.\n",
    "\n",
    "When using torchtune, several pieces of information need to be provided in a configuration file, including the type of model to use, its location, and which type of device should be utilized. The cell below generates a *.yaml* file containing all the necessary information to use Mistral 7B for inference on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mistral_generation.yaml\n",
    "\n",
    "with open(\"mistral_generation.yaml\", \"w\") as fp:\n",
    "    fp.write(\n",
    "        \"\"\"\n",
    "        # Config for running the InferenceRecipe in generate.py to generate output from an LLM\n",
    "        #\n",
    "        # To launch, run the following command from root torchtune directory:\n",
    "        #    tune run generate --config generation\n",
    "        \n",
    "        # Model arguments\n",
    "        model:\n",
    "          _component_: torchtune.models.mistral.mistral_7b\n",
    "        \n",
    "        checkpointer:\n",
    "          _component_: torchtune.utils.FullModelHFCheckpointer\n",
    "          checkpoint_dir: /home/jovyan/content/mistral-7B\n",
    "          checkpoint_files: [\n",
    "            pytorch_model-00001-of-00002.bin,\n",
    "            pytorch_model-00002-of-00002.bin\n",
    "          ]\n",
    "          recipe_checkpoint: null\n",
    "          output_dir: /home/jovyan/content/mistral-7B\n",
    "          model_type: MISTRAL\n",
    "        resume_from_checkpoint: False\n",
    "        \n",
    "        device: cuda\n",
    "        dtype: bf16\n",
    "        \n",
    "        seed: 1234\n",
    "        \n",
    "        # Tokenizer arguments\n",
    "        tokenizer:\n",
    "          _component_: torchtune.models.mistral.mistral_tokenizer\n",
    "          path: /home/jovyan/content/mistral-7B/tokenizer.model\n",
    "        \n",
    "        # Generation arguments; defaults taken from gpt-fast\n",
    "        prompt: \"Hello, my name is\"\n",
    "        max_new_tokens: 300\n",
    "        temperature: 0.6 # 0.8 and 0.6 are popular values to try\n",
    "        top_k: 300\n",
    "        \n",
    "        quantizer: null\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to get an answer from Mistral 7B to the following prompt:\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
    "\n",
    "You must output the SQL query that answers the question.\n",
    "### Input:\n",
    "Which Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\n",
    "\n",
    "### Context:\n",
    "CREATE TABLE table_name_12 (class VARCHAR, frequency_mhz VARCHAR, city_of_license VARCHAR)\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tune run generate --config ./mistral_generation.yaml \\\n",
    "prompt=\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\\n\\nYou must output the SQL query that answers the question.\\n### Input:\\nWhich Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\\n\\n### Context:\\nCREATE TABLE table_name_12 (class VARCHAR, frequency_mhz VARCHAR, city_of_license VARCHAR)\\n\\n### Response:\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dyamically get the response diplayed here and maybe lose the output above**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, using the base model, the answer is not exactly what we were hoping for. This is because the objective of the model is next word prediction.\n",
    "\n",
    "To improve the model's understanding, we will fine tune it using the Alpaca dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we need to create a configuration file that holds the relevant information to fine tune the model.\n",
    "\n",
    "LoRA (Low-Rank Adaptation), a highly efficient method of LLM fine tuning, is here used via this configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7B_lora_single_device_mistral.yaml\n",
    "\n",
    "with open(\"7B_lora_single_device_mistral.yaml\", \"w\") as fp:\n",
    "    fp.write(\n",
    "        \"\"\"\n",
    "        # Tokenizer\n",
    "        tokenizer:\n",
    "          _component_: torchtune.models.mistral.mistral_tokenizer\n",
    "          path: /home/jovyan/content/mistral-7B/tokenizer.model\n",
    "        \n",
    "        # Dataset\n",
    "        dataset:\n",
    "          _component_: torchtune.datasets.alpaca_dataset\n",
    "          train_on_input: True\n",
    "        seed: null\n",
    "        shuffle: True\n",
    "        \n",
    "        # Model Arguments\n",
    "        model:\n",
    "          _component_: torchtune.models.mistral.lora_mistral_7b\n",
    "          lora_attn_modules: ['q_proj', 'k_proj', 'v_proj']\n",
    "          apply_lora_to_mlp: True\n",
    "          apply_lora_to_output: True\n",
    "          lora_rank: 64\n",
    "          lora_alpha: 16\n",
    "        \n",
    "        checkpointer:\n",
    "          _component_: torchtune.utils.FullModelHFCheckpointer\n",
    "          checkpoint_dir: /home/jovyan/content/mistral-7B\n",
    "          checkpoint_files: [\n",
    "            pytorch_model-00001-of-00002.bin,\n",
    "            pytorch_model-00002-of-00002.bin\n",
    "          ]\n",
    "          recipe_checkpoint: null\n",
    "          output_dir: /home/jovyan/content/mistral-7B\n",
    "          model_type: MISTRAL\n",
    "        resume_from_checkpoint: False\n",
    "        \n",
    "        optimizer:\n",
    "          _component_: torch.optim.AdamW\n",
    "          lr: 2e-5\n",
    "        \n",
    "        lr_scheduler:\n",
    "          _component_: torchtune.modules.get_cosine_schedule_with_warmup\n",
    "          num_warmup_steps: 100\n",
    "        \n",
    "        loss:\n",
    "          _component_: torch.nn.CrossEntropyLoss\n",
    "        \n",
    "        # Fine-tuning arguments\n",
    "        batch_size: 4\n",
    "        epochs: 3\n",
    "        max_steps_per_epoch: null\n",
    "        gradient_accumulation_steps: 4\n",
    "        compile: False\n",
    "        \n",
    "        # Training env\n",
    "        device: cuda\n",
    "        \n",
    "        # Memory management\n",
    "        enable_activation_checkpointing: True\n",
    "        \n",
    "        # Reduced precision\n",
    "        dtype: bf16\n",
    "        \n",
    "        # Logging\n",
    "        metric_logger:\n",
    "          _component_: torchtune.utils.metric_logging.DiskLogger\n",
    "          log_dir: ${output_dir}\n",
    "        output_dir: /home/jovyan/content/mistral-7B\n",
    "        log_every_n_steps: null\n",
    "        \n",
    "        # Show case the usage of pytorch profiler\n",
    "        # Set enabled to False as it's only needed for debugging training\n",
    "        profiler:\n",
    "          _component_: torchtune.utils.profiler\n",
    "          enabled: False\n",
    "          output_dir: /home/jovyan/content/mistral-7B/torchtune_perf_tracing.json\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tune run lora_finetune_single_device --config ./7B_lora_single_device_mistral.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a NVIDIA H100 PCIe GPU, one epoch is completed in roughly 58 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference using Mistral 7B fine-tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, there is the configuration file that will be used to infere with the fine tuned version of the Mistral 7B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mistral_fine-tuned_generation.yaml\n",
    "\n",
    "with open(\"mistral_fine-tuned_generation.yaml\", \"w\") as fp:\n",
    "    fp.write(\n",
    "        \"\"\"\n",
    "        # Config for running the InferenceRecipe in generate.py to generate output from an LLM\n",
    "        #\n",
    "        # To launch, run the following command from root torchtune directory:\n",
    "        #    tune run generate --config generation\n",
    "        \n",
    "        # Model arguments\n",
    "        model:\n",
    "          _component_: torchtune.models.mistral.mistral_7b\n",
    "        \n",
    "        checkpointer:\n",
    "          _component_: torchtune.utils.FullModelHFCheckpointer\n",
    "          checkpoint_dir: /home/jovyan/content/mistral-7B\n",
    "          checkpoint_files: [\n",
    "            hf_model_0001_2.pt,\n",
    "            hf_model_0002_2.pt,\n",
    "          ]\n",
    "          recipe_checkpoint: null\n",
    "          output_dir: /home/jovyan/content/mistral-7B\n",
    "          model_type: MISTRAL\n",
    "        resume_from_checkpoint: False\n",
    "        \n",
    "        device: cuda\n",
    "        dtype: bf16\n",
    "        \n",
    "        seed: 1234\n",
    "        \n",
    "        # Tokenizer arguments\n",
    "        tokenizer:\n",
    "          _component_: torchtune.models.mistral.mistral_tokenizer\n",
    "          path: /home/jovyan/content/mistral-7B/tokenizer.model\n",
    "        \n",
    "        # Generation arguments; defaults taken from gpt-fast\n",
    "        prompt: \"Hello, my name is\"\n",
    "        max_new_tokens: 300\n",
    "        temperature: 0.6 # 0.8 and 0.6 are popular values to try\n",
    "        top_k: 300\n",
    "\n",
    "        quantizer: null\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the exact same prompt as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tune run generate --config ./mistral_fine-tuned_generation.yaml \\\n",
    "prompt=\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\\n\\nYou must output the SQL query that answers the question.\\n### Input:\\nWhich Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\\n\\n### Context:\\nCREATE TABLE table_name_12 (class VARCHAR, frequency_mhz VARCHAR, city_of_license VARCHAR)\\n\\n### Response:\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the output is more relevant, the model only outputs the answer to our question. The fine tuning process has worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
