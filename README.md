[![Datalayer](https://assets.datalayer.tech/datalayer-25.svg)](https://datalayer.io)

[![Become a Sponsor](https://img.shields.io/static/v1?label=Become%20a%20Sponsor&message=%E2%9D%A4&logo=GitHub&style=flat&color=1ABC9C)](https://github.com/sponsors/datalayer)

# Œû Datalayer Examples

This repository contains Jupyter notebook examples showcasing scenarios where [Datalayer Run](https://datalayer.run) proves highly beneficial. Datalayer Run allows you to **scale Jupyter Kernels from your local JupyterLab or CLI** to the cloud, providing the capability to run your code on powerful GPU(s) and CPU(s). Your **code** is **executed remotely**, leveraging cloud resources for enhanced performance and efficiency. üöÄ

üí° Note that you can use any notebook within Datalayer without requiring any code changes. These examples are just designed to showcase 'typical' use cases where scaling is essential.

## Getting Started 

To run the examples using Datalayer Run:

1. Clone this repository.
    ```bash
    git clone https://github.com/datalayer/examples.git datalayer-examples
    cd datalayer-examples
    ```
2. Setup Datalayer: 
  - Install the `jupyter-kernels` package in your existing environment with `pip install jupyter-kernels` (this will install JupyterLab version 4.0.10). 
  - Read the [documentation website](https://docs.datalayer.run/docs) to know more about how setup Datalayer. Don't worry, it is easy üëç <br />You just need to create an account, click on the `Datalayer Run` tile in the JupyterLab launcher, wait a bit for your Kernels to be ready, and then just assign a Remote Kernel from any Notebook kernel picker.
  
*Notebook remote execution*

<img alt="Notebook remote execution" src="test.png" width="900" />

Datalayer also support the remote execution of code using the CLI. Refer to this [page](https://datalayer.tech/docs/use/cli/) for more information.
<details>
<summary><i>CLI remote execution</i></summary>

TODO <img alt="CLI remote execution" src="https://datalayer-examples.s3.amazonaws.com/datalayer-run-examples/kernel-selector-choice.png" width="300" />
</details>

<details>
<summary><i>Switching between notebook and CLI</i></summary>

TODO <img alt="Remote notebook execution" src="https://datalayer-examples.s3.amazonaws.com/datalayer-run-examples/kernel-selector-choice.png" width="300" />

When using the same kernel, variables defined in a notebook can be used in the CLI and vice versa.

</details>

## Use cases

1. [Instruction tuning for Mistral 7B on Alpaca dataset](#mistral-instruction-tuning)
1. [Image classification model training with fast.ai](#instruction-tuning-for-mistral)
1. [Face detection on YouTube video with OpenCV](#opencv-face-detection)
1. [Mistral text generation](#mistral-text-generation)
1. ['Personalized' text-to-image model creation with Dreambooth](#dreambooth)

### [Mistral instruction tuning](https://github.com/datalayer/examples/tree/main/mistral-instruct-tuning)

**Mistral 7B** is a large language model (LLM) that contains 7.3 billion parameters and is one of the most powerful models for its size. However, this base model is not instruction-tuned, meaning it may struggle to follow instructions and perform specific tasks. The **Alpaca dataset** consists of 52,000 instructions and demonstrations generated by OpenAI's text-davinci-003 engine. These can be used for instruction tuning, helping language models to better understand and follow instructions. 

By fine-tuning Mistral 7B on the Alpaca dataset, the model will significantly improve its capabilities to perform tasks such as conversation and answering questions accurately.

This example utilizes [**torchtune**](https://github.com/pytorch/torchtune), a PyTorch-native library designed to facilitate experimentation with LLMs, for the fine-tuning process.

Due to the computational demands of fine-tuning a model, a **GPU is required**. Datalayer allows seamless integration of powerful cloud-based GPU resources, enabling efficient and scalable model training within your familiar JupyterLab.

### [Image classifier with fast.ai](https://github.com/datalayer/examples/tree/main/fastai-classifier)

This example demonstrates how to build a model that **distinguishes cats from dogs** in pictures using the fast.ai library.

<img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rAbCk0T4rksShBcPQjWC0A.gif" width="400"/>

Due to the computational demands of training a model, a **GPU is required**. Datalayer allows seamless integration of powerful cloud-based GPU resources, enabling efficient and scalable model training within your familiar JupyterLab.

### [OpenCV face detection](https://github.com/datalayer/examples/tree/main/opencv-face-detection)

This example utilizes **OpenCV** for **detecting faces** in YouTube videos. It uses a traditional Haar Cascade model, which may have limitations in accuracy compared to modern deep learning-based models.

<div style="display: flex;">
    <img src="https://datalayer-assets.s3.us-west-2.amazonaws.com/examples/rick-ashley-1.png" style="width: 20%;">
    <img src="https://datalayer-assets.s3.us-west-2.amazonaws.com/examples/rick-ashley-2.png" style="width: 20%;">
</div>

It also utilizes **parallel computing across multiple CPUs** to accelerate face detection and video processing tasks, optimizing performance and efficiency. Datalayer further enhances this capability by enabling seamless scaling across multiple CPUs.

### [Mistral text generation](https://github.com/datalayer/examples/tree/main/mistral-text-generation)

This example demonstrates how to leverage Datalayer's **GPU kernels** to accelerate text generation using **Mistral 7B Instruct v0.1**. Mistral 7B Instruct v0.1 is a instruct fine-tuned version of the Mistral-7B-v0.1 generative text model using a variety of publicly available conversation datasets.

### [Dreambooth](https://github.com/datalayer/examples/tree/main/dreambooth)

This example uses the Dreambooth method which takes as input a few images (typically 3-5 images suffice) of a subject (e.g., a specific dog) and the corresponding class name (e.g. "dog"), and returns a **fine-tuned/'personalized' text-to-image model** that encodes a unique identifier that refers to the subject. Then, at inference, the unique identifier can be implamented in different sentences to **synthesize the subjects in difference contexts** (source: [Dreambooth](https://dreambooth.github.io/)).

<img src="https://dreambooth.github.io/DreamBooth_files/accessories.png" width="500"/>

To do this fune-tuning process, **GPU is required**.